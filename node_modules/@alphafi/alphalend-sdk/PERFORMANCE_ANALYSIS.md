# Performance Analysis - getAllMarkets()

## Executive Summary

The `getAllMarkets()` function takes approximately **3 seconds** to complete. **85% of this time is spent on network I/O** across 4 sequential API calls.

## Detailed Breakdown

### Network Calls (2,577ms - 85%)

| Call | Duration | Percentage | Purpose |
|------|----------|------------|---------|
| AlphaLend GraphQL API | 918ms | 35.6% | Fetch coin metadata (symbols, decimals, price feeds) |
| Sui RPC - getDynamicFields | 462ms | 17.9% | Get list of market IDs |
| Sui RPC - multiGetObjects | 438ms | 17.0% | Fetch market objects data |
| StSui API | 758ms | 29.4% | Get stSui exchange rate |
| **Total Network** | **2,577ms** | **85.0%** | |

### CPU Processing (454ms - 15%)

- Data parsing and transformation
- Object instantiation
- SDK overhead

## Root Cause

The SDK makes **4 sequential network calls** which cannot proceed in parallel due to data dependencies. Each call must complete before the next can begin.

## Optimization Strategies

### 1. **Caching (Highest Impact) ⭐⭐⭐**

Implement caching with configurable TTL:

```typescript
// Example implementation
const cachedClient = new AlphalendClient(network, suiClient, {
  cache: {
    enabled: true,
    ttl: 30000, // 30 seconds
  }
});

// First call: ~3000ms (cache miss)
const markets1 = await cachedClient.getAllMarkets();

// Subsequent calls within TTL: <10ms (cache hit)
const markets2 = await cachedClient.getAllMarkets();
```

**Expected improvement**: 95%+ for cached requests

### 2. **Use Faster RPC Providers ⭐⭐**

Switch from public RPC to dedicated nodes:

- **Public Sui RPC**: ~450ms per call
- **Paid RPC providers** (e.g., BlockVision, Alchemy): ~100-200ms per call
- **Self-hosted full node**: ~50-100ms per call

**Expected improvement**: 40-60% on RPC calls

### 3. **Pre-initialize the Client ⭐⭐**

The GraphQL API call happens on first use. Pre-warm the client:

```typescript
const client = new AlphalendClient(network, suiClient);

// Pre-fetch coin metadata
await client.fetchCoinMetadataMap();

// Now getAllMarkets() is 918ms faster
const markets = await client.getAllMarkets();
```

**Expected improvement**: 30% by eliminating GraphQL call from critical path

### 4. **Parallel Requests Where Possible ⭐**

Some calls could potentially be parallelized:

```typescript
// Current: Sequential
// GraphQL → getDynamicFields → multiGetObjects → StSui

// Potential: Parallel
// GraphQL ────┐
// getDynamicFields ────┼──→ Process
// StSui ────┘
```

**Expected improvement**: 20-30%

### 5. **Client-Side Metadata Bundling ⭐**

Bundle coin metadata with SDK instead of fetching:

```typescript
// Instead of fetching coin metadata on every instantiation,
// bundle it in the SDK and only fetch price updates
```

**Expected improvement**: 30% by eliminating GraphQL call

### 6. **Implement WebSocket Subscriptions**

For real-time applications, use WebSocket subscriptions instead of polling:

```typescript
const subscription = await client.subscribeToMarkets((markets) => {
  // Real-time updates
});
```

**Expected improvement**: Eliminates need for repeated calls

## Recommended Implementation Priority

### Phase 1: Quick Wins (1-2 days)
1. ✅ Add caching layer with configurable TTL
2. ✅ Pre-initialize client in application startup
3. ✅ Document RPC provider recommendations

### Phase 2: Medium-term (1 week)
1. ✅ Bundle coin metadata with SDK
2. ✅ Implement parallel requests where safe
3. ✅ Add request coalescing (deduplicate simultaneous requests)

### Phase 3: Long-term (2-4 weeks)
1. ✅ WebSocket subscription support
2. ✅ Incremental updates instead of full refresh
3. ✅ Service worker for background refresh

## Testing & Monitoring

### Profiling Tools Provided

1. **scripts/profileGetAllMarkets.ts** - Basic timing analysis
2. **scripts/detailedProfile.ts** - RPC call tracking
3. **scripts/deepProfile.ts** - All network calls + breakdown

### Usage

```bash
# Run basic profiling
npx tsx scripts/profileGetAllMarkets.ts

# Run detailed RPC profiling
npx tsx scripts/detailedProfile.ts

# Run deep profiling with network call tracking
npx tsx scripts/deepProfile.ts

# Node.js V8 profiler for CPU analysis
node --prof $(which tsx) scripts/getAllMarkets.ts
node --prof-process isolate-*.log > cpu-profile.txt
```

## Expected Results After Optimization

| Scenario | Current | With Caching | Improvement |
|----------|---------|--------------|-------------|
| First call (cold) | 3,000ms | 3,000ms | 0% |
| Subsequent calls (warm) | 3,000ms | <10ms | 99.7% |
| With faster RPC | 3,000ms | 1,800ms | 40% |
| Combined optimizations | 3,000ms | <10ms (cached)<br>1,500ms (uncached) | 50-99.7% |

## Monitoring Recommendations

Track these metrics in production:

- **P50/P95/P99 latencies** for getAllMarkets()
- **Cache hit rate** (target: >90%)
- **RPC response times** by endpoint
- **Error rates** by network call
- **Time-to-interactive** for your application

## Notes

- The 15% CPU overhead (454ms) is acceptable and mostly unavoidable
- Network I/O is the primary bottleneck (85%)
- Caching provides the biggest ROI with minimal complexity
- Consider user experience: show loading states, implement progressive enhancement
